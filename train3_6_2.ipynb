{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diddIqZLm7HG",
        "outputId": "37dada9f-6651-4206-ce18-7f588c681ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=09c9b4d5f4d197b4e124e85f02e6f6942d4408f940788d4b466c996261fabaac\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n",
            "Collecting install-jdk\n",
            "  Downloading install_jdk-1.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading install_jdk-1.1.0-py3-none-any.whl (15 kB)\n",
            "Installing collected packages: install-jdk\n",
            "Successfully installed install-jdk-1.1.0\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl.metadata (352 bytes)\n",
            "Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install install-jdk\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "spark = (SparkSession.builder\n",
        ".appName(\"MySparkApp\")\n",
        ".getOrCreate())"
      ],
      "metadata": {
        "id": "i0lUYU--nFdR"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random as rnd\n",
        "import datetime as dt\n",
        "\n",
        "n=1000\n",
        "rnd.seed()\n",
        "dates=[]\n",
        "for i in range(0,n):\n",
        "  d=dt.date(dt.date.today().year,rnd.randint(1,12),rnd.randint(1,28))\n",
        "  dates.append(d.strftime(\"%Y-%m-%d\"))\n",
        "#print(dates)\n",
        "counts=[rnd.randint(1,11) for i in range(0,n)]\n",
        "#print(counts)\n",
        "prices=[rnd.randint(1,500) for i in range(0,n)]\n",
        "#print(prices)\n",
        "users=[rnd.randint(100,1000) for i in range(0,n)]\n",
        "#print(users)\n",
        "prod=[\"apple\",\"milk\",\"potatoes\",\"bread\",\"fish\"]\n",
        "prods=[rnd.choice(prod) for i in range(0,n)]\n",
        "#print(prods)\n",
        "\n",
        "#my_data=[(a,b,c,d,e) for a in dates for b in users for c in prods for d in counts for e in prices]\n",
        "my_data=[]\n",
        "for i in range(0,n):\n",
        "  d=(dates[i],users[i],prods[i],counts[i],prices[i])\n",
        "  my_data.append(d)\n",
        "#print(my_data)"
      ],
      "metadata": {
        "id": "BPf16dThqkbq"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([\n",
        "    StructField(\"Data\", StringType(), True),\n",
        "    StructField(\"UserID\", IntegerType(), True),\n",
        "    StructField(\"Product\", StringType(), True),\n",
        "    StructField(\"Count\", IntegerType(), True),\n",
        "    StructField(\"Price\", IntegerType(), True)\n",
        "])\n",
        "df=spark.createDataFrame(my_data, schema)\n",
        "df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkREGepEnTjf",
        "outputId": "938a860e-0fa8-4103-c9f6-3d87c78e084d"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------+--------+-----+-----+\n",
            "|      Data|UserID| Product|Count|Price|\n",
            "+----------+------+--------+-----+-----+\n",
            "|2024-06-05|   256|    milk|    9|    5|\n",
            "|2024-02-07|   644|    fish|    7|  270|\n",
            "|2024-05-18|   291|   apple|    6|  299|\n",
            "|2024-05-18|   879|potatoes|    9|  306|\n",
            "|2024-08-18|   433|    milk|    2|  434|\n",
            "|2024-10-16|   915|    fish|    4|  104|\n",
            "|2024-10-02|   746|   bread|    7|  184|\n",
            "|2024-09-07|   390|potatoes|    1|  259|\n",
            "|2024-01-07|   126|   bread|    9|  229|\n",
            "|2024-12-23|   853|   bread|    4|  437|\n",
            "|2024-11-02|   149|    milk|    5|  300|\n",
            "|2024-01-05|   254|    fish|    1|  106|\n",
            "|2024-11-09|   239|potatoes|    2|  408|\n",
            "|2024-05-24|   908|potatoes|    5|  349|\n",
            "|2024-07-17|   582|    milk|    9|  143|\n",
            "|2024-05-15|   337|   apple|    9|   36|\n",
            "|2024-02-26|   138|   bread|   10|  152|\n",
            "|2024-07-23|   320|    fish|    7|  313|\n",
            "|2024-03-27|   454|    fish|    3|  190|\n",
            "|2024-08-12|   863|   bread|    9|   70|\n",
            "+----------+------+--------+-----+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.mode(\"overwrite\").option(\"header\",True).csv(\"my_output\")"
      ],
      "metadata": {
        "id": "13IFH1B8qyaB"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "9swlNroxq0RP"
      },
      "execution_count": 134,
      "outputs": []
    }
  ]
}