# -*- coding: utf-8 -*-
"""train3-6-2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1To49pmqQNKgrknI5utbNffX33t6HL-vP
"""

!pip install pyspark
!pip install install-jdk
!pip install findspark

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

spark = (SparkSession.builder
.appName("MySparkApp")
.getOrCreate())

import random as rnd
import datetime as dt

n=1000
rnd.seed()
dates=[]
for i in range(0,n):
  d=dt.date(dt.date.today().year,rnd.randint(1,12),rnd.randint(1,28))
  dates.append(d.strftime("%Y-%m-%d"))
#print(dates)
counts=[rnd.randint(1,11) for i in range(0,n)]
#print(counts)
prices=[rnd.randint(1,500) for i in range(0,n)]
#print(prices)
users=[rnd.randint(100,1000) for i in range(0,n)]
#print(users)
prod=["apple","milk","potatoes","bread","fish"]
prods=[rnd.choice(prod) for i in range(0,n)]
#print(prods)

#my_data=[(a,b,c,d,e) for a in dates for b in users for c in prods for d in counts for e in prices]
my_data=[]
for i in range(0,n):
  d=(dates[i],users[i],prods[i],counts[i],prices[i])
  my_data.append(d)
#print(my_data)

schema = StructType([
    StructField("Data", StringType(), True),
    StructField("UserID", IntegerType(), True),
    StructField("Product", StringType(), True),
    StructField("Count", IntegerType(), True),
    StructField("Price", IntegerType(), True)
])
df=spark.createDataFrame(my_data, schema)
df.show()

df.write.mode("overwrite").option("header",True).csv("my_output")

spark.stop()